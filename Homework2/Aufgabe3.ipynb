{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
      "        [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
      "        [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],\n",
      "        [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],\n",
      "        [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],\n",
      "        [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],\n",
      "        [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],\n",
      "        [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],\n",
      "        [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],\n",
      "        [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]])\n",
      "tensor([[11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "        [71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "        [81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "        [91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "(10, 1)\n",
      "torch.Size([9, 9])\n",
      "11\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/g4sgs1kn7w763_44_b21v97w0000gn/T/ipykernel_38123/3872334105.py:14: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  id(a.storage()) == id(a_transpose.storage())\n",
      "/var/folders/k7/g4sgs1kn7w763_44_b21v97w0000gn/T/ipykernel_38123/3872334105.py:29: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread('cat.jpeg')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mismatch in length of strides and shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m img_arr\u001b[39m.\u001b[39mshape\n\u001b[1;32m     32\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(img_arr)\n\u001b[0;32m---> 34\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mas_strided(img,(\u001b[39m400\u001b[39;49m,\u001b[39m600\u001b[39;49m,\u001b[39m3\u001b[39;49m),(\u001b[39m128\u001b[39;49m,))\n\u001b[1;32m     36\u001b[0m plt\u001b[39m.\u001b[39mimshow(img)\n\u001b[1;32m     37\u001b[0m plt\u001b[39m.\u001b[39mimshow(t)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mismatch in length of strides and shape"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = torch.tensor(np.arange(0,100).reshape([10,10]))\n",
    "print(a)\n",
    "\n",
    "a_transpose = a.transpose(0, 1)\n",
    "\n",
    "print(a_transpose)\n",
    "\n",
    "id(a.storage()) == id(a_transpose.storage())\n",
    "\n",
    "c = a[1:,1:]\n",
    "\n",
    "print(c)\n",
    "print(c.stride())\n",
    "print(c.size())\n",
    "\n",
    "print(c.storage_offset())\n",
    "\n",
    "x = torch.tensor(np.identity(10))\n",
    "print(x)\n",
    "\n",
    "x_inverse = torch.inverse(x)\n",
    "\n",
    "img_arr = imageio.imread('cat.jpeg')\n",
    "img_arr.shape\n",
    "\n",
    "img = torch.from_numpy(img_arr)\n",
    "\n",
    "t = torch.as_strided(img,(400,600,3),(,)) # hier schauen mit bytes\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.imshow(t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
